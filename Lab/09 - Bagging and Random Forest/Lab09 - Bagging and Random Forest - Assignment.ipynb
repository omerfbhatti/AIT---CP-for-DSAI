{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe16f670",
   "metadata": {},
   "source": [
    "# Programming for Data Science and Artificial Intelligence\n",
    "\n",
    "## Supervised Learning - Classification - Bagging and Random Forests\n",
    "\n",
    "### Readings: \n",
    "- [GERON] Ch7\n",
    "- [VANDER] Ch5\n",
    "- [HASTIE] Ch15\n",
    "- https://scikit-learn.org/stable/modules/ensemble.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3321d0",
   "metadata": {},
   "source": [
    "### Lab09 - Assignment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54b741a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name = \"Muhammad Omer Farooq Bhatti\"\n",
    "Id = \"122498\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d039c6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf6a6c1",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "\n",
    "A single decision tree does not perform well as it tends to overfit.  A possible solution is the construct multiple trees to reduce variances.  To make sure each tree is not exactly learning the same thing since it will then be all same trees, we need to inject some differences to these trees (i.e., make them as diverse as possible but at the same time they also see some overlappinp samples).  One simple idea is that each of the tree is trained on a subset of **bootstrapping sample** and then perform some sort of aggregation of the decision.\n",
    "\n",
    "The process has the following steps:\n",
    "\n",
    "1. Sample $m$ times **with replacement** from the original training data\n",
    "2. Repeat $B$ times to generate $B$ \"boostrapped\" training datasets $D_1, D_2, \\cdots, D_B$\n",
    "3. Train $B$ trees using the training datasets $D_1, D_2, \\cdots, D_B$ \n",
    "\n",
    "Boostrapping the data plus performing some sort of aggregation (averaging or majority votes) is called **boostrap aggregation** or **bagging**.\n",
    "\n",
    "*Example*:\n",
    "\n",
    "Assume that we have a training set where $m=4$, and $n=2$:\n",
    "\n",
    "$$D = {(x_1, y_1), (x_2, y_2), (x_3, y_3), (x_4, y_4)}$$\n",
    "\n",
    "We generate, say, $B = 3$ datasets by boostrapping:\n",
    "\n",
    "$$D_1 = {(x_1, y_1), (x_2, y_2), (x_3, y_3), (x_3, y_3)}$$\n",
    "$$D_2 = {(x_1, y_1), (x_4, y_4), (x_4, y_4), (x_3, y_3)}$$\n",
    "$$D_3 = {(x_1, y_1), (x_1, y_1), (x_2, y_2), (x_2, y_2)}$$\n",
    "\n",
    "We can then train 3 trees.\n",
    "\n",
    "Note: When sampling is performed **without** replacement, it is called **pasting**.  In other words, both bagging and pasting allow training instacnes to be sampled several times across multiple predictors, but only bagging allows training instances to be sampled several times for the same predictor.\n",
    "\n",
    "Let's try to code from scratch.  To make our life easier, we shall use DecisionTree from the sklearn library (since we already code it from scratch in the previous class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2371ff",
   "metadata": {},
   "source": [
    "### ===Task===\n",
    "\n",
    "#### Out of Bag Evaluation\n",
    "\n",
    "Well, it seems like our bagging technique is quite good.  Anyhow, one interesting observation is that each tree only see a subset of the dataset. Any data that a particular tree did not see is called **out of bag** (oob).  Note that oob is not the same for all predictors.\n",
    "\n",
    "One interesting thing is that since oob is something that each tree never see, thus oob is somewhat a validation set.  Thus what we can do is after we fit each tree. We can ask each tree to test their accuracy with their own oob, and then we can average the accuracy from all trees.  \n",
    "\n",
    "Let's modify the above scratch code to:\n",
    "- Calculate for oob evaluation for each bootstrapped dataset, and also the average score\n",
    "- Change the code to \"without replacement\"\n",
    "- Put everything into a class <code>Bagging</code>.  It should have at least two methods, <code>fit(X_train, y_train)</code>, and <code>predict(X_test)</code>\n",
    "- Modify the code from above to randomize features.  Set the number of features to be used in each tree to be <code>sqrt(n)</code>, and then select a subset of features for each tree.  This can be easily done by setting our DecisionTreeClassifier <code>max_features</code> to 'sqrt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb56370e",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "\n",
    "So far, it seems bagging works well.  However, the $B$ bootstrapped dataset are correlated, thus the power of variance reduction is diminished.  How do we further de-correlate these $B$ trees?\n",
    "\n",
    "A **random forest** is constructed by bagging, but for each split in each tree, only a random subset of $q \\leq n$ features are considered as splitting variables.\n",
    "\n",
    "Rule of thumb: $q = \\sqrt{n}$ for classification trees and $q = \\frac{n}{3}$ for regression trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc02eee",
   "metadata": {},
   "source": [
    "\n",
    "1. https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier\n",
    "2. https://numpy.org/doc/stable/reference/random/generated/numpy.random.randint.html\n",
    "3. https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mode.html#scipy.stats.mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e1978c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bagging:\n",
    "    def __init__(self, b=5, bootstrap_ratio = 1.0, \n",
    "                 tree_parameters = {'max_depth':2, 'criterion':'gini', 'min_samples_split':5, 'max_features':'sqrt'}):\n",
    "        #Defining the number of classifiers to be used\n",
    "        self.B=b\n",
    "        #Ratio of total training samples to be used to train a classifier\n",
    "        self.bootstrap_ratio = bootstrap_ratio  #all of them\n",
    "\n",
    "        #### CREATING DECISION TREE CLASSIFIERS FOR BAGGING\n",
    "        #max_depth = depth of the tree\n",
    "        #criterion = criteria for finding the best split of a node\n",
    "        #min_samples_split = The minimum number of samples required to split an internal node\n",
    "        self.classifiers = []\n",
    "        for i in range(0,self.B):\n",
    "            self.classifiers.append( DecisionTreeClassifier(**tree_parameters) )  #using keyword arguments\n",
    "\n",
    "    def fit(self, X, y, with_replacement=True):\n",
    "        #defining sample size in case bootstrap_ratio != 1\n",
    "        self.sample_size = int(self.bootstrap_ratio * X.shape[0])\n",
    "        print(\"Bagging with replacement: \", with_replacement)\n",
    "        print(\"Using sample size: \", self.sample_size)\n",
    "        #defining the matrices xsamples and ysamples which will hold the bootstrapped training data for all trees\n",
    "        self.bootstrapped_xsamples = np.zeros((self.B, self.sample_size, X.shape[1]))\n",
    "        self.bootstrapped_ysamples = np.zeros((self.B, self.sample_size))\n",
    "        \n",
    "        #sample data from X and y and fill bootstrap matrices, returns indexes of not used training samples\n",
    "        notused_idx = self._bootstrap_samples(X, y, with_replacement)\n",
    "        print(\"not used indexes: \", notused_idx)\n",
    "              \n",
    "        #Fitting dTrees to training samples and doing Out of Bag Evaluation\n",
    "        accuracy=[]\n",
    "        for i, classifier in enumerate(self.classifiers):\n",
    "            xtrain = self.bootstrapped_xsamples[i,:]     #training samples for ith tree\n",
    "            ytrain = self.bootstrapped_ysamples[i]\n",
    "            classifier.fit(xtrain, ytrain)\n",
    "            print(f\"Completed training classifier {i}\")\n",
    "            xtest = X[notused_idx[i]]         #sampling X, y using the not used indexes to create test set\n",
    "            ytest = y[notused_idx[i]]         #for each classifier\n",
    "            yhat = classifier.predict(xtest)\n",
    "            accuracy.append(np.sum(yhat==ytest)/ytest.shape[0])      #Calculating accuracy\n",
    "        print(\"\\nAccuracy of classifiers using oob training data: \", accuracy)\n",
    "        print(\"Average Accuracy of classifiers: \", np.mean(accuracy))\n",
    "        \n",
    "            \n",
    "    def predict(self, X_test):\n",
    "        #Defining y_predicted matrix to hold predictions from each classifier\n",
    "        y_predicted = np.zeros((self.B, X_test.shape[0]))\n",
    "        #Getting predictions from each classifier\n",
    "        for b, classifier in enumerate(self.classifiers):  \n",
    "            y_predicted[b,:] = classifier.predict(X_test)\n",
    "        #Getting the most common prediction (if tie, then smaller value)\n",
    "        #print(y_predicted)\n",
    "        y_predicted = stats.mode(y_predicted, axis=0)[0][0]  #along axis=0 -> meaning across classifiers\n",
    "        return y_predicted\n",
    "        \n",
    "    def _bootstrap_samples(self, X, y, with_replacement=True):\n",
    "        notused_sample_idx_alltrainigsets = []\n",
    "        for b in range(0,self.B):      #For every Decision Tree Classifier\n",
    "            used_sample_idx = []       #reset used index list for every tree\n",
    "            for sample in range(0, self.sample_size):     #For every training sample for the tree\n",
    "                sample_idx = np.random.randint(0, X.shape[0])    #Get a random sample index\n",
    "                if with_replacement==False:\n",
    "                    while (sample_idx in used_sample_idx):             #Loop until unused index found\n",
    "                        sample_idx = np.random.randint(0, X.shape[0])\n",
    "                used_sample_idx.append(sample_idx)                          #Keep a list of used indexes\n",
    "                self.bootstrapped_xsamples[b, sample, :] = X[sample_idx]\n",
    "                self.bootstrapped_ysamples[b, sample] = y[sample_idx]\n",
    "            #for bootstrap_ratio = 1.0 without replacement, all samples are used for training each tree\n",
    "            notused_sample_idx_alltrainigsets.append( \n",
    "                [idx for idx in range(0, self.sample_size) if idx not in used_sample_idx] ) \n",
    "        return notused_sample_idx_alltrainigsets        #For out of bag evaluation later\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30d02b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "X,y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "model = bagging(b=5, bootstrap_ratio = 0.90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84e80c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging with replacement:  True\n",
      "Using sample size:  94\n",
      "not used indexes:  [[1, 2, 6, 7, 10, 15, 16, 20, 21, 25, 26, 27, 32, 33, 35, 36, 39, 41, 43, 45, 48, 49, 51, 54, 57, 58, 59, 60, 61, 63, 67, 68, 71, 72, 78, 81, 86, 87, 91], [1, 3, 5, 6, 10, 16, 19, 24, 25, 26, 28, 30, 33, 40, 42, 43, 45, 46, 52, 54, 56, 59, 61, 62, 65, 68, 69, 70, 72, 73, 74, 78, 79, 84, 85, 88, 89, 90], [0, 1, 4, 5, 7, 8, 9, 11, 15, 22, 25, 28, 29, 32, 35, 36, 41, 44, 46, 47, 49, 52, 53, 54, 56, 57, 61, 64, 67, 68, 69, 75, 77, 79, 81, 83, 85, 86, 88, 93], [1, 3, 5, 6, 8, 9, 11, 13, 19, 20, 21, 22, 29, 31, 32, 33, 36, 37, 38, 46, 47, 49, 50, 52, 54, 56, 57, 59, 63, 67, 69, 70, 76, 77, 79, 82, 83, 84, 87, 93], [0, 4, 10, 12, 15, 16, 17, 18, 21, 22, 24, 29, 30, 32, 33, 34, 35, 39, 40, 42, 46, 47, 58, 60, 63, 65, 66, 67, 68, 70, 72, 73, 75, 79, 82, 83, 91]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.9487179487179487, 0.9210526315789473, 0.825, 0.95, 0.918918918918919]\n",
      "Average Accuracy of classifiers:  0.9127378998431631\n",
      "\n",
      "yhat:  [2. 1. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, with_replacement=True)\n",
    "yhat=model.predict(X_test)\n",
    "print(\"\\nyhat: \", yhat)\n",
    "print(\"\\nAccuracy with Bagging: \")\n",
    "print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b98bcea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging with replacement:  False\n",
      "Using sample size:  94\n",
      "not used indexes:  [[10, 27, 67, 69, 70, 73, 83, 87, 88, 90], [3, 15, 20, 24, 45, 59, 72, 92, 93], [0, 3, 24, 34, 39, 54, 77, 79], [7, 18, 20, 30, 49, 66, 78, 88, 90], [16, 24, 32, 40, 52, 71, 74]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.8, 1.0, 1.0, 1.0, 0.7142857142857143]\n",
      "Average Accuracy of classifiers:  0.9028571428571428\n",
      "\n",
      "yhat:  [2. 1. 0. 2. 1. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Pasting: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.94      0.94      0.94        18\n",
      "           2       0.91      0.91      0.91        11\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.95      0.95      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, with_replacement=False)\n",
    "yhat=model.predict(X_test)\n",
    "print(\"\\nyhat: \", yhat)\n",
    "print(\"\\nAccuracy with Pasting: \")\n",
    "print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aae31ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.89      0.94        18\n",
      "           2       0.85      1.00      0.92        11\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.95      0.96      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "classifier1 = BaggingClassifier(tree, n_estimators=5, max_samples=0.99)\n",
    "\n",
    "classifier1.fit(X_train, y_train)\n",
    "yhat = classifier1.predict(X_test)\n",
    "print(\"Bagging Accuracy: \")\n",
    "print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8661c035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasting Accuracy: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree2 = DecisionTreeClassifier()\n",
    "\n",
    "#pasting\n",
    "parameters = {'base_estimator': tree2, 'n_estimators':5, 'max_samples':0.99, 'bootstrap':False}\n",
    "classifier2 = BaggingClassifier(**parameters)\n",
    "\n",
    "classifier2.fit(X_train, y_train)\n",
    "yhat = classifier2.predict(X_test)\n",
    "print(\"Pasting Accuracy: \")\n",
    "print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2ab35cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging with replacement:  True\n",
      "Using sample size:  63\n",
      "not used indexes:  [[0, 1, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 16, 19, 21, 22, 26, 27, 28, 36, 37, 38, 39, 40, 44, 46, 47, 50, 52, 53, 54, 57, 58, 59, 60, 61], [0, 1, 2, 3, 4, 5, 10, 11, 12, 13, 14, 16, 18, 22, 23, 24, 25, 26, 27, 28, 31, 34, 38, 39, 40, 44, 45, 47, 49, 50, 52, 53, 54, 55, 57, 59, 61, 62], [0, 1, 2, 4, 6, 7, 11, 12, 15, 17, 19, 20, 24, 26, 27, 29, 30, 31, 33, 36, 37, 38, 39, 40, 41, 42, 43, 45, 47, 49, 52, 54, 55, 57, 58, 62], [1, 6, 7, 8, 11, 15, 16, 17, 18, 20, 21, 23, 24, 25, 27, 28, 29, 30, 31, 32, 34, 37, 38, 40, 41, 42, 43, 44, 45, 46, 51, 53, 54, 57, 58, 59, 60, 61]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.918918918918919, 0.8157894736842105, 0.8611111111111112, 0.7368421052631579]\n",
      "Average Accuracy of classifiers:  0.8331654022443497\n",
      "\n",
      "yhat:  [2. 1. 0. 1. 1. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 1. 1. 0. 1. 0. 2. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 4, bootstrap_ratio=0.6): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.86      1.00      0.92        18\n",
      "           2       1.00      0.73      0.84        11\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.95      0.91      0.92        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  73\n",
      "not used indexes:  [[1, 2, 3, 4, 5, 8, 12, 13, 14, 17, 18, 21, 22, 23, 28, 33, 34, 35, 37, 38, 39, 40, 41, 43, 45, 47, 50, 52, 53, 54, 55, 57, 58, 60, 61, 64, 65, 67, 71, 72], [0, 1, 3, 5, 6, 8, 11, 15, 16, 17, 19, 20, 23, 24, 27, 28, 29, 31, 34, 35, 36, 37, 39, 40, 42, 46, 49, 54, 60, 61, 62, 63, 66, 67, 68, 70], [1, 2, 4, 6, 7, 8, 9, 10, 18, 20, 21, 23, 24, 29, 34, 36, 37, 38, 39, 46, 48, 50, 51, 52, 58, 59, 61, 63, 64, 66, 67, 69, 70, 72], [0, 1, 3, 5, 9, 12, 14, 15, 16, 19, 20, 21, 25, 26, 29, 30, 31, 33, 36, 37, 42, 44, 45, 47, 50, 51, 52, 53, 54, 56, 59, 61, 62, 63, 67, 68, 70, 72]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.95, 0.9722222222222222, 0.8235294117647058, 0.9210526315789473]\n",
      "Average Accuracy of classifiers:  0.9167010663914689\n",
      "\n",
      "yhat:  [2. 1. 0. 2. 1. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 2. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 2. 1. 2. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 4, bootstrap_ratio=0.7): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.94      0.83      0.88        18\n",
      "           2       0.77      0.91      0.83        11\n",
      "\n",
      "    accuracy                           0.91        45\n",
      "   macro avg       0.90      0.91      0.91        45\n",
      "weighted avg       0.92      0.91      0.91        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  84\n",
      "not used indexes:  [[0, 2, 5, 8, 10, 12, 14, 15, 17, 19, 21, 22, 23, 27, 29, 35, 39, 41, 44, 45, 46, 47, 49, 50, 53, 56, 59, 60, 65, 72, 73, 74, 75, 77, 79], [1, 3, 4, 11, 12, 13, 17, 21, 22, 23, 24, 25, 29, 34, 35, 37, 38, 39, 41, 45, 47, 48, 52, 53, 55, 58, 61, 62, 64, 66, 69, 70, 72, 74, 75, 76, 80, 81, 83], [4, 6, 7, 11, 14, 16, 20, 23, 24, 26, 30, 32, 33, 34, 35, 36, 37, 40, 41, 44, 45, 46, 47, 49, 50, 51, 53, 55, 57, 62, 65, 66, 67, 69, 70, 71, 73, 75, 77, 78, 79, 81], [1, 2, 3, 5, 10, 11, 13, 16, 19, 20, 22, 26, 27, 28, 30, 31, 32, 33, 38, 39, 41, 42, 43, 44, 45, 46, 47, 50, 52, 57, 58, 59, 64, 66, 68, 70, 73, 74, 78]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.9714285714285714, 0.9487179487179487, 0.9047619047619048, 0.8974358974358975]\n",
      "Average Accuracy of classifiers:  0.9305860805860805\n",
      "\n",
      "yhat:  [2. 1. 0. 1. 1. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 1. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 4, bootstrap_ratio=0.8): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.85      0.94      0.89        18\n",
      "           2       0.89      0.73      0.80        11\n",
      "\n",
      "    accuracy                           0.91        45\n",
      "   macro avg       0.91      0.89      0.90        45\n",
      "weighted avg       0.91      0.91      0.91        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  94\n",
      "not used indexes:  [[2, 4, 5, 8, 9, 13, 16, 19, 20, 25, 26, 30, 31, 34, 35, 38, 40, 41, 44, 45, 46, 47, 48, 52, 54, 61, 62, 65, 67, 69, 70, 72, 73, 74, 76, 77, 78, 82, 84, 85, 88], [0, 2, 4, 7, 11, 15, 16, 18, 20, 24, 26, 31, 34, 35, 36, 37, 43, 45, 47, 50, 51, 52, 53, 55, 61, 62, 63, 65, 67, 68, 69, 71, 73, 75, 80, 86, 88, 93], [0, 1, 4, 9, 13, 14, 15, 16, 19, 20, 21, 22, 28, 30, 31, 35, 40, 42, 44, 48, 50, 51, 52, 56, 59, 60, 62, 63, 65, 69, 71, 77, 78, 79, 81, 82], [1, 4, 5, 6, 7, 8, 10, 13, 15, 17, 18, 20, 22, 25, 26, 31, 35, 37, 40, 42, 46, 49, 51, 52, 56, 58, 59, 60, 63, 66, 68, 69, 71, 75, 77, 79, 81, 82, 84, 85, 87, 91]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.9024390243902439, 0.9210526315789473, 0.9722222222222222, 0.9285714285714286]\n",
      "Average Accuracy of classifiers:  0.9310713266907105\n",
      "\n",
      "yhat:  [2. 1. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 4, bootstrap_ratio=0.9): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        18\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  105\n",
      "not used indexes:  [[1, 2, 6, 8, 12, 15, 16, 17, 18, 20, 22, 25, 26, 29, 30, 31, 37, 43, 52, 61, 62, 63, 64, 66, 71, 72, 74, 75, 77, 80, 81, 82, 87, 89, 93, 95, 97, 98, 99, 102], [7, 10, 11, 13, 15, 16, 19, 20, 21, 27, 28, 33, 34, 35, 37, 38, 43, 44, 45, 48, 51, 53, 57, 59, 63, 70, 71, 72, 75, 76, 77, 79, 81, 82, 86, 95, 96, 97, 98, 99, 100, 101, 104], [0, 2, 4, 6, 10, 11, 12, 19, 22, 24, 27, 28, 30, 40, 41, 42, 44, 50, 51, 52, 59, 60, 61, 68, 72, 74, 75, 77, 84, 86, 87, 89, 90, 98, 100, 101, 103, 104], [0, 3, 8, 12, 15, 16, 19, 23, 27, 30, 31, 33, 35, 40, 41, 45, 49, 50, 52, 57, 58, 62, 63, 64, 66, 70, 72, 73, 74, 77, 79, 81, 82, 86, 87, 91, 92, 93, 96, 102]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.925, 0.9302325581395349, 0.9736842105263158, 0.8]\n",
      "Average Accuracy of classifiers:  0.9072291921664628\n",
      "\n",
      "yhat:  [1. 2. 0. 2. 1. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 2. 2. 0. 2.\n",
      " 2. 0. 1. 1. 2. 1. 0. 2. 0. 2. 1. 0. 1. 0. 2. 1. 1. 2. 1. 2. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 4, bootstrap_ratio=1.0): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.79      0.61      0.69        18\n",
      "           2       0.53      0.73      0.62        11\n",
      "\n",
      "    accuracy                           0.78        45\n",
      "   macro avg       0.77      0.78      0.77        45\n",
      "weighted avg       0.80      0.78      0.78        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  63\n",
      "not used indexes:  [[6, 7, 8, 11, 13, 14, 16, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 33, 36, 39, 40, 41, 42, 45, 48, 49, 50, 51, 52, 53, 55, 56, 57, 60, 62], [0, 5, 6, 9, 15, 17, 19, 21, 22, 26, 27, 29, 32, 33, 34, 37, 38, 39, 41, 44, 45, 46, 47, 49, 51, 52, 54, 56, 58, 59, 60, 61], [1, 2, 4, 6, 7, 8, 11, 17, 18, 22, 23, 24, 28, 29, 30, 31, 32, 34, 37, 38, 40, 42, 43, 45, 47, 49, 50, 52, 54, 57, 62], [0, 2, 4, 6, 7, 10, 11, 12, 13, 14, 17, 18, 19, 23, 25, 27, 29, 32, 33, 37, 39, 42, 44, 47, 48, 49, 51, 53, 57, 58, 59, 60], [0, 1, 2, 3, 4, 8, 9, 10, 12, 14, 15, 17, 18, 19, 21, 23, 24, 25, 26, 29, 30, 31, 33, 35, 36, 38, 40, 42, 47, 49, 50, 51, 52, 53, 56, 57, 58, 60]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.9142857142857143, 0.90625, 0.6451612903225806, 0.9375, 0.9473684210526315]\n",
      "Average Accuracy of classifiers:  0.8701130851321853\n",
      "\n",
      "yhat:  [2. 1. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 2. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 2. 1. 2. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 5, bootstrap_ratio=0.6): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.83      0.91        18\n",
      "           2       0.79      1.00      0.88        11\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.94      0.93        45\n",
      "weighted avg       0.95      0.93      0.93        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  73\n",
      "not used indexes:  [[1, 3, 9, 13, 14, 16, 17, 19, 26, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 44, 45, 48, 49, 51, 52, 55, 57, 58, 62, 65, 66, 67, 68, 72], [3, 5, 7, 8, 12, 13, 17, 19, 22, 25, 26, 27, 28, 30, 32, 33, 35, 38, 39, 41, 42, 43, 47, 48, 51, 52, 54, 56, 57, 59, 60, 64, 65, 66, 67, 70, 71, 72], [0, 3, 4, 6, 7, 8, 10, 11, 12, 19, 21, 22, 23, 26, 27, 31, 32, 33, 36, 39, 40, 42, 45, 47, 48, 49, 52, 53, 54, 55, 58, 64, 66, 67, 70, 71], [0, 1, 6, 8, 10, 15, 20, 23, 25, 26, 28, 30, 31, 32, 34, 35, 36, 38, 39, 41, 43, 44, 45, 46, 48, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 65, 66, 69], [0, 3, 6, 9, 14, 15, 20, 23, 26, 27, 28, 31, 33, 34, 38, 39, 42, 44, 45, 46, 48, 49, 55, 56, 57, 60, 61, 65, 66, 67, 68, 69, 70, 72]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.8529411764705882, 0.9210526315789473, 0.9444444444444444, 0.8780487804878049, 0.9117647058823529]\n",
      "Average Accuracy of classifiers:  0.9016503477728277\n",
      "\n",
      "yhat:  [2. 1. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 5, bootstrap_ratio=0.7): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        18\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  84\n",
      "not used indexes:  [[0, 1, 5, 9, 10, 13, 14, 17, 18, 19, 21, 22, 26, 33, 34, 40, 42, 46, 47, 48, 49, 51, 52, 55, 56, 57, 60, 62, 63, 64, 65, 66, 70, 71, 75, 77, 79, 80, 82], [1, 7, 10, 13, 14, 19, 20, 23, 26, 28, 29, 32, 33, 34, 36, 37, 38, 39, 40, 43, 44, 46, 47, 49, 51, 54, 56, 58, 62, 63, 68, 69, 72, 75, 76, 77, 78, 81, 83], [0, 2, 5, 11, 13, 14, 19, 24, 25, 26, 27, 31, 32, 34, 36, 42, 45, 46, 50, 51, 55, 56, 57, 58, 59, 62, 65, 69, 72, 74, 77, 78, 80, 82, 83], [0, 1, 2, 3, 6, 10, 12, 13, 14, 15, 16, 18, 19, 20, 25, 27, 29, 31, 32, 33, 38, 39, 40, 41, 42, 46, 48, 51, 53, 54, 59, 60, 64, 65, 66, 67, 68, 70, 72, 73, 76, 79, 81, 83], [0, 2, 4, 8, 12, 14, 16, 17, 20, 22, 23, 26, 34, 37, 39, 42, 44, 48, 49, 51, 53, 54, 58, 59, 63, 64, 66, 71, 73, 76, 77, 78, 80, 82, 83]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.9743589743589743, 0.9230769230769231, 0.9714285714285714, 0.9318181818181818, 0.9714285714285714]\n",
      "Average Accuracy of classifiers:  0.9544222444222443\n",
      "\n",
      "yhat:  [2. 1. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 1. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 5, bootstrap_ratio=0.8): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.94      0.94      0.94        18\n",
      "           2       0.91      0.91      0.91        11\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.95      0.95      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  94\n",
      "not used indexes:  [[0, 1, 6, 8, 9, 12, 14, 15, 16, 21, 22, 23, 24, 26, 29, 30, 34, 35, 37, 41, 49, 50, 52, 53, 54, 56, 58, 59, 70, 73, 78, 79, 83, 84, 91], [3, 4, 5, 6, 9, 10, 15, 21, 22, 23, 24, 30, 32, 34, 41, 42, 43, 48, 51, 53, 54, 57, 58, 59, 61, 63, 68, 71, 72, 75, 78, 81, 82, 83, 87, 90, 91, 92, 93], [4, 7, 9, 10, 12, 13, 19, 24, 25, 28, 33, 36, 43, 47, 51, 52, 54, 57, 59, 61, 62, 63, 64, 65, 66, 69, 70, 75, 76, 78, 80, 81, 84, 85, 86, 87, 88, 92], [4, 6, 7, 9, 10, 11, 12, 15, 16, 20, 21, 22, 24, 27, 38, 39, 41, 45, 52, 56, 58, 61, 63, 64, 66, 69, 72, 79, 82, 84, 86, 89, 92], [1, 3, 5, 6, 10, 13, 14, 15, 17, 20, 22, 24, 25, 26, 28, 33, 37, 43, 45, 47, 48, 51, 54, 59, 63, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 89, 90, 93]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed training classifier 4\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.9714285714285714, 1.0, 0.9736842105263158, 0.7575757575757576, 0.9487179487179487]\n",
      "Average Accuracy of classifiers:  0.9302812976497188\n",
      "\n",
      "yhat:  [2. 1. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 2. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 2. 1. 2. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 5, bootstrap_ratio=0.9): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.83      0.91        18\n",
      "           2       0.79      1.00      0.88        11\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.94      0.93        45\n",
      "weighted avg       0.95      0.93      0.93        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  105\n",
      "not used indexes:  [[1, 4, 10, 12, 13, 17, 21, 22, 24, 29, 32, 33, 34, 36, 42, 43, 44, 45, 48, 50, 51, 53, 55, 57, 58, 61, 62, 63, 65, 66, 68, 81, 82, 85, 87, 88, 91, 94, 95, 99], [2, 10, 12, 13, 14, 16, 17, 19, 21, 25, 28, 32, 33, 39, 41, 47, 50, 52, 56, 60, 61, 62, 65, 70, 72, 74, 75, 81, 82, 84, 88, 90, 91, 93, 94, 95, 97, 98, 99], [1, 2, 7, 8, 11, 15, 19, 23, 24, 27, 31, 33, 36, 38, 39, 41, 43, 44, 45, 46, 47, 48, 50, 52, 55, 59, 60, 64, 65, 67, 69, 70, 75, 79, 80, 82, 83, 88, 91, 93, 94, 97, 99, 103], [4, 5, 6, 7, 9, 10, 12, 13, 14, 18, 24, 27, 30, 33, 36, 37, 42, 46, 48, 49, 51, 52, 54, 55, 56, 58, 59, 60, 70, 71, 75, 78, 80, 81, 86, 88, 95, 98, 100, 103, 104], [0, 4, 7, 9, 26, 28, 29, 30, 35, 38, 50, 53, 55, 58, 63, 64, 65, 70, 71, 72, 77, 78, 79, 86, 87, 88, 89, 95, 96, 97, 98, 99, 103]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.925, 0.9487179487179487, 0.8636363636363636, 0.975609756097561, 0.7575757575757576]\n",
      "Average Accuracy of classifiers:  0.8941079652055262\n",
      "\n",
      "yhat:  [2. 2. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 2. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 5, bootstrap_ratio=1.0): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.83      0.91        18\n",
      "           2       0.79      1.00      0.88        11\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.94      0.93        45\n",
      "weighted avg       0.95      0.93      0.93        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  63\n",
      "not used indexes:  [[3, 7, 8, 9, 16, 18, 19, 20, 23, 24, 25, 26, 27, 28, 31, 33, 34, 35, 37, 39, 40, 41, 47, 50, 52, 54, 57, 58, 59, 60], [0, 1, 3, 5, 7, 8, 9, 10, 13, 14, 16, 18, 21, 25, 29, 31, 34, 36, 37, 38, 43, 46, 48, 50, 53, 54, 55, 58, 59, 61, 62], [1, 3, 4, 6, 7, 8, 9, 10, 12, 14, 15, 16, 17, 19, 20, 21, 22, 24, 25, 27, 28, 29, 32, 33, 34, 36, 38, 41, 42, 43, 44, 48, 49, 51, 56, 58, 60, 61], [0, 4, 5, 6, 7, 10, 13, 14, 15, 16, 17, 19, 20, 22, 23, 24, 30, 31, 34, 39, 40, 41, 43, 47, 48, 50, 53, 54, 56, 58, 59, 62], [0, 3, 5, 9, 10, 14, 16, 17, 21, 22, 26, 27, 28, 29, 30, 32, 34, 35, 37, 38, 39, 40, 44, 46, 49, 52, 53, 55, 57, 59], [1, 3, 5, 9, 11, 12, 14, 15, 17, 18, 21, 23, 24, 26, 30, 32, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 54, 55, 56, 57, 58, 59, 60, 61, 62]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "Completed training classifier 5\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.9, 0.7096774193548387, 0.8157894736842105, 0.96875, 0.9, 0.9210526315789473]\n",
      "Average Accuracy of classifiers:  0.8692115874363328\n",
      "\n",
      "yhat:  [2. 1. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 6, bootstrap_ratio=0.6): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  73\n",
      "not used indexes:  [[0, 1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 14, 16, 19, 20, 21, 22, 24, 25, 27, 29, 34, 35, 38, 40, 45, 46, 52, 53, 55, 56, 60, 61, 62, 63, 67, 69, 70, 71], [0, 5, 7, 9, 10, 13, 15, 17, 18, 22, 23, 28, 31, 32, 33, 34, 35, 37, 38, 43, 46, 47, 49, 50, 51, 52, 53, 55, 56, 58, 61, 63, 66, 69, 70, 71, 72], [0, 2, 3, 6, 10, 15, 17, 18, 19, 20, 21, 23, 25, 27, 28, 36, 37, 39, 40, 41, 42, 43, 47, 49, 51, 52, 56, 58, 59, 60, 61, 62, 63, 64, 66, 69, 70, 71], [1, 3, 7, 9, 11, 14, 15, 16, 17, 21, 22, 24, 25, 27, 29, 31, 32, 33, 35, 40, 43, 48, 50, 53, 54, 59, 60, 62, 63, 64, 66, 68, 71], [0, 1, 2, 4, 5, 7, 8, 10, 18, 19, 21, 22, 25, 26, 27, 32, 36, 38, 39, 40, 44, 45, 46, 47, 51, 54, 56, 58, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72], [3, 4, 6, 7, 11, 13, 14, 15, 16, 21, 22, 23, 25, 28, 29, 32, 33, 37, 39, 40, 41, 42, 49, 50, 51, 54, 55, 61, 63, 64, 66, 70, 71, 72]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "Completed training classifier 5\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.9230769230769231, 0.972972972972973, 0.9210526315789473, 0.9393939393939394, 0.8974358974358975, 0.9117647058823529]\n",
      "Average Accuracy of classifiers:  0.9276161783901723\n",
      "\n",
      "yhat:  [2. 1. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 6, bootstrap_ratio=0.7): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  84\n",
      "not used indexes:  [[0, 1, 2, 4, 6, 7, 8, 10, 13, 18, 19, 22, 26, 28, 32, 33, 37, 39, 42, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 63, 64, 67, 72, 74, 76, 78, 80, 81, 83], [0, 2, 12, 14, 16, 18, 20, 21, 22, 23, 25, 27, 29, 30, 33, 37, 39, 41, 42, 43, 45, 46, 48, 49, 52, 54, 57, 61, 68, 70, 77, 79, 81, 82, 83], [0, 1, 3, 6, 8, 9, 11, 12, 13, 19, 20, 21, 22, 25, 29, 30, 31, 39, 42, 45, 47, 50, 51, 54, 55, 58, 59, 66, 67, 68, 70, 73, 75, 76, 77, 79, 83], [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 14, 18, 21, 22, 24, 30, 32, 35, 36, 37, 41, 43, 45, 47, 48, 51, 52, 53, 54, 57, 58, 62, 64, 73, 74, 78, 80, 81, 82], [1, 2, 3, 9, 10, 11, 14, 16, 18, 19, 21, 22, 23, 24, 25, 28, 29, 31, 32, 33, 38, 39, 40, 41, 43, 46, 49, 53, 54, 57, 58, 62, 64, 65, 69, 70, 73, 76, 82], [2, 3, 4, 8, 9, 11, 15, 16, 17, 18, 20, 23, 24, 26, 27, 29, 30, 31, 32, 33, 35, 38, 39, 40, 43, 44, 46, 47, 48, 49, 50, 51, 52, 57, 58, 67, 68, 69, 70, 72, 76, 81, 83]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "Completed training classifier 5\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.9743589743589743, 0.9714285714285714, 0.9459459459459459, 0.7692307692307693, 0.9230769230769231, 0.7674418604651163]\n",
      "Average Accuracy of classifiers:  0.8919138407510502\n",
      "\n",
      "yhat:  [2. 2. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 2. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 6, bootstrap_ratio=0.8): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.83      0.91        18\n",
      "           2       0.79      1.00      0.88        11\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.94      0.93        45\n",
      "weighted avg       0.95      0.93      0.93        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  94\n",
      "not used indexes:  [[3, 4, 6, 9, 12, 13, 15, 16, 18, 20, 22, 24, 25, 29, 30, 33, 36, 40, 41, 42, 43, 46, 47, 48, 49, 52, 54, 56, 70, 71, 73, 85, 89, 90, 93], [3, 5, 6, 11, 20, 21, 23, 24, 25, 26, 31, 33, 35, 36, 41, 42, 44, 45, 49, 58, 59, 60, 64, 65, 66, 72, 77, 78, 79, 80, 81, 82, 84, 86, 88, 89, 90, 92], [1, 2, 3, 5, 11, 14, 17, 25, 29, 30, 36, 39, 43, 45, 50, 53, 55, 57, 58, 60, 62, 63, 66, 69, 70, 71, 72, 73, 75, 77, 78, 81, 82, 87, 88, 89, 90, 93], [5, 8, 10, 11, 12, 16, 23, 25, 29, 30, 31, 33, 36, 38, 39, 40, 41, 50, 53, 55, 57, 60, 62, 66, 67, 69, 70, 71, 87, 89, 90, 91, 93], [6, 7, 8, 11, 12, 15, 18, 21, 24, 25, 27, 28, 33, 35, 36, 37, 39, 43, 44, 46, 50, 53, 54, 56, 58, 60, 61, 63, 65, 66, 67, 74, 79, 82, 89], [4, 12, 13, 14, 15, 16, 18, 20, 21, 24, 28, 33, 35, 37, 40, 41, 43, 45, 46, 48, 49, 54, 56, 57, 58, 61, 66, 69, 73, 76, 77, 80, 83, 84, 88, 89, 92, 93]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "Completed training classifier 5\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.9142857142857143, 0.868421052631579, 0.9210526315789473, 0.7878787878787878, 0.9714285714285714, 0.9736842105263158]\n",
      "Average Accuracy of classifiers:  0.9061251613883193\n",
      "\n",
      "yhat:  [2. 1. 0. 2. 1. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 2. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 2. 1. 2. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 6, bootstrap_ratio=0.9): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.94      0.83      0.88        18\n",
      "           2       0.77      0.91      0.83        11\n",
      "\n",
      "    accuracy                           0.91        45\n",
      "   macro avg       0.90      0.91      0.91        45\n",
      "weighted avg       0.92      0.91      0.91        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  105\n",
      "not used indexes:  [[0, 4, 5, 6, 9, 12, 13, 14, 15, 21, 22, 25, 26, 29, 33, 40, 41, 42, 46, 48, 50, 52, 55, 56, 59, 61, 63, 65, 67, 68, 69, 76, 78, 79, 80, 81, 83, 86, 92, 93, 98, 100, 102], [2, 3, 4, 12, 13, 14, 18, 20, 21, 22, 25, 26, 27, 28, 30, 31, 32, 34, 40, 43, 48, 49, 51, 52, 57, 63, 67, 68, 70, 71, 76, 77, 79, 86, 87, 89, 90, 92, 95, 99, 102, 104], [1, 2, 6, 7, 15, 16, 18, 21, 22, 23, 25, 26, 27, 31, 33, 34, 38, 42, 43, 46, 47, 54, 55, 59, 61, 63, 64, 65, 70, 74, 75, 82, 85, 87, 89, 95, 97, 99, 103], [5, 6, 9, 11, 15, 17, 22, 29, 30, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 56, 58, 61, 62, 64, 67, 71, 73, 82, 84, 88, 91, 94, 97, 99, 101, 103, 104], [0, 4, 9, 12, 13, 14, 16, 19, 20, 22, 30, 32, 33, 35, 37, 39, 40, 43, 45, 49, 51, 52, 55, 56, 60, 66, 67, 68, 70, 75, 76, 79, 87, 89, 93, 95, 99, 100, 103], [2, 5, 12, 16, 23, 25, 34, 35, 37, 38, 39, 45, 49, 54, 58, 60, 63, 64, 67, 69, 70, 71, 72, 77, 78, 81, 85, 89, 90, 91, 98, 100, 101, 104]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "Completed training classifier 5\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.9069767441860465, 0.9047619047619048, 0.8974358974358975, 0.9473684210526315, 0.9230769230769231, 0.8529411764705882]\n",
      "Average Accuracy of classifiers:  0.9054268444973319\n",
      "\n",
      "yhat:  [2. 1. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 6, bootstrap_ratio=1.0): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  63\n",
      "not used indexes:  [[1, 3, 6, 7, 8, 10, 12, 16, 17, 20, 22, 23, 26, 28, 30, 31, 32, 33, 35, 36, 38, 39, 40, 42, 43, 44, 45, 46, 47, 48, 52, 53, 54, 55, 58, 59, 61], [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 21, 22, 24, 25, 27, 28, 30, 32, 33, 39, 40, 41, 42, 44, 45, 47, 49, 55, 56, 58, 59, 60, 62], [1, 6, 7, 9, 10, 11, 12, 13, 18, 20, 23, 24, 25, 26, 27, 29, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 50, 54, 57, 58, 59, 60, 62], [0, 4, 6, 8, 9, 10, 13, 15, 17, 23, 25, 26, 30, 31, 33, 34, 35, 36, 38, 40, 41, 42, 43, 45, 46, 47, 48, 50, 51, 53, 55, 56, 58, 59, 62], [4, 5, 6, 7, 8, 10, 12, 13, 14, 15, 17, 18, 19, 22, 23, 24, 25, 27, 31, 32, 33, 35, 37, 40, 43, 47, 48, 49, 50, 52, 53, 54, 57, 59, 60, 61], [0, 4, 5, 6, 7, 9, 10, 11, 12, 16, 17, 18, 19, 20, 24, 26, 28, 30, 31, 33, 34, 35, 36, 37, 38, 48, 49, 51, 52, 53, 61, 62], [1, 3, 5, 6, 7, 8, 9, 10, 11, 16, 17, 18, 19, 22, 23, 24, 27, 28, 29, 32, 33, 35, 37, 39, 40, 47, 51, 52, 53, 54, 55]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "Completed training classifier 5\n",
      "Completed training classifier 6\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.918918918918919, 0.868421052631579, 0.8823529411764706, 0.8857142857142857, 0.9444444444444444, 0.9375, 0.8064516129032258]\n",
      "Average Accuracy of classifiers:  0.8919718936841321\n",
      "\n",
      "yhat:  [2. 1. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 7, bootstrap_ratio=0.6): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        18\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  73\n",
      "not used indexes:  [[0, 1, 3, 4, 5, 7, 8, 11, 13, 15, 16, 17, 20, 21, 23, 27, 28, 30, 32, 35, 36, 41, 42, 43, 45, 46, 49, 50, 51, 56, 59, 61, 62, 65, 66, 68, 69, 71, 72], [0, 1, 3, 5, 6, 7, 8, 12, 14, 16, 17, 19, 25, 26, 31, 32, 33, 34, 35, 36, 37, 41, 46, 47, 51, 54, 56, 57, 58, 64, 65, 66, 67, 70, 72], [4, 7, 8, 9, 12, 13, 16, 19, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 36, 38, 39, 42, 44, 46, 49, 50, 52, 54, 55, 57, 58, 63, 65, 67, 68, 70], [1, 3, 4, 12, 13, 14, 16, 19, 21, 22, 28, 29, 32, 33, 34, 36, 40, 41, 43, 47, 48, 50, 54, 55, 56, 57, 60, 61, 63, 64, 65, 67, 68, 71, 72], [0, 3, 5, 9, 10, 14, 17, 19, 20, 22, 24, 25, 27, 30, 32, 38, 39, 40, 43, 47, 51, 52, 54, 57, 58, 60, 61, 62, 63, 67, 68, 69, 70, 72], [2, 5, 7, 11, 12, 15, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 33, 39, 41, 45, 46, 47, 48, 50, 52, 53, 55, 61, 63, 64, 67, 69, 72], [1, 3, 4, 8, 11, 14, 15, 16, 18, 19, 23, 24, 25, 26, 27, 30, 31, 34, 37, 39, 43, 44, 45, 46, 47, 48, 52, 57, 59, 62, 63, 64, 65, 67, 72]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "Completed training classifier 5\n",
      "Completed training classifier 6\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.9743589743589743, 0.9428571428571428, 0.8918918918918919, 0.8857142857142857, 0.8235294117647058, 0.9444444444444444, 0.9428571428571428]\n",
      "Average Accuracy of classifiers:  0.9150933276983697\n",
      "\n",
      "yhat:  [2. 1. 0. 2. 1. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 7, bootstrap_ratio=0.7): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.94      0.94      0.94        18\n",
      "           2       0.91      0.91      0.91        11\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.95      0.95      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not used indexes:  [[3, 4, 5, 6, 11, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 27, 28, 29, 31, 33, 34, 36, 37, 43, 47, 53, 54, 56, 57, 61, 62, 67, 69, 70, 73, 74, 75, 79], [0, 4, 6, 8, 9, 10, 11, 13, 19, 20, 23, 24, 25, 28, 33, 34, 39, 41, 44, 45, 49, 50, 51, 53, 55, 56, 60, 61, 63, 64, 66, 67, 68, 69, 70, 71, 73, 76, 79, 82], [1, 2, 3, 7, 8, 9, 10, 11, 17, 18, 19, 26, 28, 29, 31, 35, 36, 39, 40, 41, 47, 49, 52, 53, 54, 58, 59, 61, 62, 63, 65, 72, 73, 74, 77, 79, 81], [1, 2, 3, 5, 9, 10, 11, 12, 15, 16, 18, 19, 20, 21, 22, 25, 27, 29, 39, 40, 41, 42, 44, 48, 50, 52, 53, 54, 55, 58, 60, 61, 66, 70, 74, 75, 77, 79, 83], [0, 1, 4, 6, 9, 10, 17, 18, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 34, 39, 40, 41, 42, 43, 45, 46, 50, 51, 54, 55, 58, 59, 60, 61, 62, 65, 68, 69, 71, 74, 77, 82], [4, 5, 7, 10, 11, 12, 13, 15, 16, 17, 21, 23, 28, 32, 34, 39, 41, 49, 50, 54, 61, 63, 66, 68, 70, 71, 72, 76, 79, 82, 83], [0, 4, 5, 6, 8, 12, 13, 16, 17, 19, 20, 21, 22, 25, 35, 36, 37, 39, 44, 45, 46, 49, 50, 51, 53, 54, 55, 56, 58, 59, 60, 63, 66, 69, 70, 71, 74, 75, 79, 80, 81, 82, 83]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "Completed training classifier 5\n",
      "Completed training classifier 6\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.9736842105263158, 0.975, 0.8918918918918919, 0.7948717948717948, 0.9523809523809523, 0.967741935483871, 0.9302325581395349]\n",
      "Average Accuracy of classifiers:  0.9265433347563372\n",
      "\n",
      "yhat:  [2. 1. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 7, bootstrap_ratio=0.8): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  94\n",
      "not used indexes:  [[1, 7, 10, 11, 15, 19, 21, 22, 23, 25, 26, 31, 32, 37, 38, 40, 43, 45, 52, 56, 60, 62, 63, 64, 71, 72, 73, 76, 79, 80, 81, 86, 87, 89, 91], [1, 6, 10, 11, 15, 16, 17, 18, 20, 23, 27, 28, 33, 35, 37, 39, 42, 45, 46, 52, 54, 56, 57, 58, 63, 66, 73, 75, 76, 78, 79, 80, 81, 82, 84, 87, 89, 90], [1, 2, 4, 11, 13, 14, 15, 17, 24, 28, 34, 36, 37, 46, 47, 49, 50, 51, 54, 55, 61, 63, 64, 66, 70, 72, 74, 75, 82, 84, 93], [0, 3, 5, 10, 14, 15, 17, 22, 23, 24, 26, 30, 33, 34, 37, 38, 41, 43, 45, 50, 51, 53, 54, 55, 57, 58, 59, 60, 62, 71, 75, 76, 77, 79, 82, 83, 84, 85, 86, 87, 91], [4, 5, 7, 8, 14, 16, 17, 18, 19, 20, 23, 25, 26, 28, 30, 32, 34, 36, 37, 38, 39, 44, 45, 56, 61, 65, 71, 73, 74, 76, 78, 83, 87, 88, 91], [1, 3, 10, 13, 26, 27, 28, 30, 32, 34, 35, 36, 37, 44, 50, 51, 53, 59, 60, 62, 64, 65, 72, 73, 74, 75, 80, 83, 86, 90, 93], [0, 2, 3, 6, 8, 12, 13, 14, 15, 17, 18, 22, 23, 24, 26, 28, 29, 30, 33, 35, 46, 49, 52, 53, 54, 55, 58, 59, 60, 61, 65, 66, 70, 71, 74, 75, 76, 78, 80, 81, 82, 83, 88, 91, 92]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "Completed training classifier 5\n",
      "Completed training classifier 6\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.8857142857142857, 0.868421052631579, 1.0, 1.0, 0.8857142857142857, 0.8709677419354839, 0.9777777777777777]\n",
      "Average Accuracy of classifiers:  0.9269421633962018\n",
      "\n",
      "yhat:  [2. 2. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 1. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 7, bootstrap_ratio=0.9): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.94      0.89      0.91        18\n",
      "           2       0.83      0.91      0.87        11\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.92      0.93      0.93        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  105\n",
      "not used indexes:  [[0, 3, 4, 5, 9, 11, 13, 18, 19, 24, 33, 34, 37, 40, 42, 47, 51, 56, 58, 62, 63, 64, 66, 70, 71, 72, 74, 75, 79, 80, 84, 86, 87, 88, 89, 91, 92, 93, 100, 101, 103], [4, 7, 8, 14, 16, 20, 21, 24, 29, 30, 31, 32, 33, 35, 38, 40, 45, 48, 51, 61, 64, 66, 67, 68, 70, 73, 78, 80, 84, 86, 87, 89, 91, 96, 97, 98, 99, 101], [2, 9, 10, 11, 13, 14, 15, 16, 19, 24, 25, 26, 29, 31, 33, 34, 36, 40, 41, 46, 47, 49, 52, 54, 56, 57, 63, 67, 70, 73, 76, 77, 82, 89, 90, 91, 93, 94, 97, 98, 99, 103], [1, 3, 4, 6, 10, 16, 17, 22, 23, 27, 29, 31, 33, 35, 36, 37, 40, 44, 46, 51, 52, 55, 64, 66, 72, 73, 74, 78, 81, 83, 84, 85, 86, 87, 88, 91, 96, 100, 102, 104], [1, 2, 7, 13, 14, 20, 21, 22, 25, 34, 35, 36, 37, 41, 44, 46, 47, 52, 54, 55, 56, 58, 60, 61, 67, 69, 75, 76, 79, 81, 82, 83, 84, 86, 87, 90, 97, 101, 102], [0, 3, 4, 5, 7, 9, 23, 24, 25, 28, 31, 40, 42, 43, 44, 49, 50, 51, 53, 54, 56, 57, 58, 59, 62, 66, 67, 68, 71, 72, 79, 80, 81, 84, 85, 87, 91, 92, 93, 96, 100, 101, 103], [0, 3, 5, 16, 18, 20, 23, 26, 29, 32, 38, 41, 43, 46, 47, 53, 55, 59, 60, 61, 64, 67, 68, 70, 71, 72, 74, 77, 79, 81, 83, 87, 90, 91, 93, 95, 97, 99, 100, 101]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "Completed training classifier 5\n",
      "Completed training classifier 6\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.9024390243902439, 0.8947368421052632, 0.9285714285714286, 0.95, 0.9743589743589743, 0.9534883720930233, 0.925]\n",
      "Average Accuracy of classifiers:  0.9326563773598476\n",
      "\n",
      "yhat:  [2. 2. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 2. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 7, bootstrap_ratio=1.0): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.83      0.91        18\n",
      "           2       0.79      1.00      0.88        11\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.94      0.93        45\n",
      "weighted avg       0.95      0.93      0.93        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  63\n",
      "not used indexes:  [[0, 2, 3, 4, 5, 6, 9, 11, 12, 14, 15, 18, 19, 21, 23, 24, 25, 27, 31, 32, 33, 37, 39, 41, 44, 47, 50, 54, 55, 58, 60, 61, 62], [1, 5, 6, 7, 9, 10, 12, 13, 14, 16, 17, 19, 20, 22, 23, 25, 27, 30, 32, 33, 36, 37, 38, 39, 40, 44, 45, 50, 51, 56, 57, 61, 62], [0, 1, 5, 6, 8, 9, 13, 14, 16, 19, 20, 23, 24, 26, 27, 28, 29, 30, 31, 33, 35, 36, 39, 40, 41, 48, 49, 51, 52, 53, 54, 55, 58, 62], [0, 1, 4, 5, 6, 7, 9, 11, 18, 19, 21, 23, 24, 25, 26, 27, 28, 29, 32, 34, 35, 36, 38, 40, 41, 43, 44, 46, 48, 49, 53, 54, 55, 58], [2, 3, 6, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 34, 35, 36, 37, 43, 44, 45, 46, 48, 49, 50, 53, 54, 56, 57, 60, 61], [3, 4, 5, 6, 7, 8, 10, 11, 12, 15, 16, 18, 19, 21, 22, 24, 26, 30, 32, 33, 34, 35, 36, 37, 41, 42, 45, 46, 49, 50, 51, 55, 56, 58], [0, 1, 3, 5, 6, 7, 11, 12, 13, 16, 19, 20, 25, 26, 27, 28, 29, 30, 33, 34, 36, 39, 40, 42, 45, 48, 51, 52, 53, 54, 58, 59], [0, 2, 3, 4, 5, 6, 9, 10, 11, 18, 23, 27, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 41, 42, 43, 49, 50, 51, 52, 54, 56, 57, 62]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "Completed training classifier 5\n",
      "Completed training classifier 6\n",
      "Completed training classifier 7\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.9696969696969697, 0.9393939393939394, 0.8529411764705882, 0.9117647058823529, 0.8947368421052632, 0.9705882352941176, 0.9375, 0.9696969696969697]\n",
      "Average Accuracy of classifiers:  0.9307898548175251\n",
      "\n",
      "yhat:  [2. 1. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 8, bootstrap_ratio=0.6): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  73\n",
      "not used indexes:  [[0, 2, 4, 5, 6, 8, 11, 12, 14, 15, 16, 17, 18, 20, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 38, 40, 41, 44, 49, 51, 52, 53, 54, 58, 60, 61, 64, 65, 69, 70, 71, 72], [1, 4, 7, 9, 10, 11, 13, 15, 18, 19, 20, 22, 24, 25, 26, 27, 29, 30, 31, 34, 35, 37, 38, 42, 44, 47, 54, 56, 57, 59, 60, 61, 62, 63, 64, 65, 67, 69, 70, 71], [0, 1, 3, 4, 5, 7, 10, 11, 12, 14, 17, 21, 22, 24, 27, 30, 34, 36, 37, 39, 42, 43, 47, 48, 51, 54, 56, 57, 58, 59, 60, 61, 67, 68, 71], [0, 3, 4, 7, 8, 9, 11, 12, 14, 15, 16, 17, 20, 21, 23, 25, 26, 28, 29, 30, 33, 37, 40, 41, 42, 45, 46, 48, 49, 51, 55, 57, 58, 59, 61, 62, 67, 71, 72], [2, 5, 6, 7, 8, 10, 11, 12, 14, 16, 17, 18, 20, 21, 23, 24, 25, 27, 28, 31, 32, 34, 35, 37, 40, 42, 45, 47, 49, 50, 52, 53, 56, 57, 58, 60, 66, 70, 72], [0, 5, 6, 8, 12, 13, 14, 15, 18, 19, 21, 23, 27, 28, 29, 31, 33, 36, 37, 39, 40, 42, 44, 45, 47, 52, 54, 56, 57, 61, 71, 72], [1, 2, 3, 6, 9, 10, 11, 12, 13, 14, 15, 21, 23, 25, 26, 27, 28, 29, 31, 32, 33, 34, 36, 40, 43, 46, 49, 50, 51, 54, 55, 56, 57, 58, 59, 60, 61, 68, 70, 71, 72], [0, 1, 3, 4, 5, 7, 12, 15, 17, 21, 22, 23, 24, 25, 26, 28, 30, 31, 32, 34, 38, 41, 46, 48, 49, 51, 55, 56, 57, 59, 62, 63, 64, 65, 66, 68, 71]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "Completed training classifier 5\n",
      "Completed training classifier 6\n",
      "Completed training classifier 7\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.9302325581395349, 0.8, 0.8285714285714286, 0.9487179487179487, 0.8717948717948718, 0.9375, 0.926829268292683, 0.918918918918919]\n",
      "Average Accuracy of classifiers:  0.8953206243044232\n",
      "\n",
      "yhat:  [2. 2. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 2. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 8, bootstrap_ratio=0.7): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.83      0.91        18\n",
      "           2       0.79      1.00      0.88        11\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.94      0.93        45\n",
      "weighted avg       0.95      0.93      0.93        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  84\n",
      "not used indexes:  [[0, 1, 2, 7, 8, 9, 11, 13, 20, 21, 22, 29, 30, 36, 37, 41, 45, 47, 50, 51, 53, 56, 57, 58, 61, 62, 64, 65, 66, 67, 71, 73, 78, 79, 80, 81], [3, 4, 7, 9, 10, 11, 12, 16, 18, 25, 26, 28, 30, 33, 34, 35, 40, 43, 44, 45, 47, 49, 50, 52, 54, 55, 56, 60, 61, 64, 66, 70, 72, 75, 81, 82, 83], [5, 6, 15, 17, 18, 19, 22, 24, 26, 27, 28, 31, 32, 36, 39, 40, 44, 45, 48, 53, 54, 57, 58, 60, 64, 65, 68, 69, 70, 71, 72, 73, 78], [0, 6, 8, 12, 15, 18, 20, 22, 23, 25, 27, 30, 32, 35, 41, 42, 43, 45, 47, 48, 52, 54, 56, 57, 60, 64, 65, 66, 68, 74, 76, 77, 78], [2, 3, 4, 5, 7, 9, 11, 20, 21, 22, 24, 25, 28, 29, 31, 32, 35, 38, 42, 44, 46, 50, 51, 53, 56, 57, 59, 60, 61, 62, 64, 68, 71, 73, 75, 76, 77, 78, 83], [0, 1, 2, 3, 4, 5, 7, 8, 9, 10, 13, 14, 16, 20, 21, 22, 24, 27, 29, 31, 32, 37, 44, 46, 49, 50, 54, 57, 62, 64, 65, 66, 67, 68, 69, 70, 73, 74, 75, 79, 80, 82, 83], [2, 4, 5, 8, 9, 13, 17, 18, 20, 21, 22, 24, 25, 26, 27, 29, 34, 35, 38, 41, 42, 44, 46, 49, 51, 55, 56, 57, 58, 63, 65, 66, 70, 74, 76, 77, 78, 81, 83], [1, 3, 6, 7, 11, 12, 13, 16, 17, 21, 23, 25, 29, 30, 32, 34, 35, 41, 42, 45, 48, 51, 52, 54, 55, 56, 57, 58, 60, 61, 65, 67, 68, 72, 74, 75, 77, 79, 81, 83]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "Completed training classifier 5\n",
      "Completed training classifier 6\n",
      "Completed training classifier 7\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.8611111111111112, 0.972972972972973, 0.9393939393939394, 0.9696969696969697, 0.9487179487179487, 0.7441860465116279, 0.8974358974358975, 0.95]\n",
      "Average Accuracy of classifiers:  0.9104393607300585\n",
      "\n",
      "yhat:  [2. 2. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 2. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 8, bootstrap_ratio=0.8): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.83      0.91        18\n",
      "           2       0.79      1.00      0.88        11\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.94      0.93        45\n",
      "weighted avg       0.95      0.93      0.93        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  94\n",
      "not used indexes:  [[1, 3, 5, 6, 7, 10, 11, 16, 18, 19, 20, 21, 23, 24, 28, 29, 32, 37, 38, 39, 41, 44, 45, 52, 54, 58, 62, 63, 64, 67, 68, 71, 72, 73, 77, 83, 84, 85, 86, 92], [2, 5, 7, 12, 13, 16, 19, 25, 30, 31, 33, 38, 40, 41, 44, 46, 47, 48, 52, 53, 55, 57, 58, 59, 61, 64, 66, 68, 73, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 88, 92], [0, 5, 8, 13, 16, 17, 21, 22, 24, 25, 26, 28, 29, 30, 32, 33, 36, 47, 48, 51, 53, 62, 68, 72, 74, 75, 77, 82, 90, 93], [4, 5, 6, 7, 8, 9, 11, 16, 18, 19, 23, 24, 25, 27, 30, 31, 33, 35, 36, 37, 39, 41, 43, 46, 54, 55, 56, 57, 61, 64, 65, 72, 74, 76, 77, 79, 80, 82, 87, 92], [1, 2, 5, 7, 10, 11, 12, 16, 18, 19, 25, 27, 30, 31, 36, 37, 38, 43, 47, 48, 51, 55, 56, 59, 61, 63, 64, 65, 70, 72, 76, 77, 79, 80, 81, 85, 90], [2, 7, 8, 10, 11, 12, 13, 15, 17, 19, 21, 26, 28, 38, 39, 42, 48, 49, 50, 51, 52, 55, 59, 60, 62, 65, 70, 74, 75, 76, 77, 78, 80, 84, 87, 90, 92], [2, 3, 6, 7, 10, 12, 14, 16, 17, 19, 22, 23, 26, 29, 30, 32, 33, 36, 38, 40, 42, 43, 44, 46, 52, 55, 62, 64, 70, 74, 76, 77, 79, 80, 84, 85, 89, 90, 91], [0, 2, 3, 5, 7, 11, 12, 13, 14, 24, 28, 29, 32, 36, 38, 39, 40, 44, 46, 48, 50, 51, 58, 59, 61, 62, 65, 67, 70, 74, 76, 78, 79, 81, 82, 84, 86, 89, 90, 91, 93]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "Completed training classifier 5\n",
      "Completed training classifier 6\n",
      "Completed training classifier 7\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.95, 0.926829268292683, 0.9, 0.975, 0.972972972972973, 0.918918918918919, 0.6923076923076923, 0.9512195121951219]\n",
      "Average Accuracy of classifiers:  0.9109060455859237\n",
      "\n",
      "yhat:  [2. 1. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 8, bootstrap_ratio=0.9): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        18\n",
      "           2       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  105\n",
      "not used indexes:  [[1, 2, 6, 7, 8, 14, 16, 17, 18, 21, 26, 28, 30, 32, 33, 35, 37, 39, 43, 53, 55, 70, 72, 75, 80, 85, 87, 88, 89, 90, 91, 92, 95, 97, 100, 102], [0, 2, 3, 5, 6, 16, 17, 19, 22, 23, 26, 30, 32, 34, 35, 36, 38, 41, 44, 45, 47, 48, 49, 50, 53, 54, 55, 62, 65, 66, 69, 73, 75, 76, 77, 79, 80, 82, 91, 96, 99, 101, 102], [2, 4, 5, 7, 8, 9, 10, 13, 18, 21, 30, 32, 34, 35, 37, 38, 40, 43, 44, 47, 49, 50, 52, 53, 56, 61, 65, 66, 68, 69, 76, 77, 78, 80, 85, 88, 90, 93, 94, 95, 103], [1, 4, 7, 9, 11, 12, 13, 17, 21, 22, 23, 26, 30, 31, 32, 34, 36, 37, 39, 46, 49, 50, 53, 55, 56, 62, 64, 68, 70, 71, 73, 74, 75, 81, 82, 84, 86, 87, 90, 93, 98], [5, 8, 11, 12, 13, 14, 18, 19, 21, 22, 26, 28, 30, 32, 34, 37, 43, 45, 48, 60, 62, 64, 70, 71, 76, 78, 80, 86, 90, 91, 97, 99], [0, 2, 7, 8, 12, 14, 15, 18, 21, 22, 25, 26, 27, 31, 32, 34, 42, 44, 45, 47, 55, 56, 61, 64, 65, 66, 67, 69, 70, 75, 76, 78, 79, 80, 82, 87, 90, 94, 100, 101, 102, 103], [2, 3, 4, 5, 7, 8, 9, 11, 13, 17, 18, 25, 27, 28, 29, 33, 38, 45, 47, 48, 50, 52, 53, 56, 57, 59, 60, 62, 63, 66, 67, 70, 71, 76, 81, 83, 85, 86, 90, 98], [5, 9, 11, 17, 19, 20, 22, 23, 24, 25, 26, 27, 30, 31, 37, 38, 42, 44, 45, 47, 48, 52, 56, 57, 61, 62, 63, 67, 71, 72, 76, 80, 86, 94, 95, 96, 98, 99, 100, 103]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "Completed training classifier 5\n",
      "Completed training classifier 6\n",
      "Completed training classifier 7\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.9722222222222222, 0.9069767441860465, 0.9512195121951219, 0.9512195121951219, 0.9375, 0.9285714285714286, 0.95, 0.975]\n",
      "Average Accuracy of classifiers:  0.9465886774212426\n",
      "\n",
      "yhat:  [2. 1. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 8, bootstrap_ratio=1.0): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  63\n",
      "not used indexes:  [[0, 1, 3, 4, 5, 8, 9, 10, 15, 16, 17, 21, 23, 24, 25, 26, 28, 29, 30, 33, 35, 36, 39, 40, 41, 43, 45, 47, 49, 51, 54, 55, 57, 58, 60, 61], [2, 3, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 22, 23, 24, 25, 26, 28, 30, 32, 38, 39, 43, 46, 48, 50, 52, 53, 54, 55, 57, 61], [0, 1, 2, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 23, 25, 27, 28, 29, 31, 32, 35, 37, 39, 40, 45, 48, 54, 55, 57, 58, 59], [1, 4, 6, 9, 15, 17, 18, 20, 21, 22, 23, 25, 27, 31, 34, 35, 36, 38, 40, 41, 44, 45, 47, 50, 51, 52, 53, 55, 56, 61], [0, 1, 2, 3, 4, 6, 7, 9, 11, 18, 19, 20, 26, 28, 29, 30, 31, 33, 34, 35, 37, 38, 40, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 61, 62], [2, 4, 5, 10, 11, 12, 14, 15, 16, 17, 18, 20, 23, 25, 26, 27, 29, 30, 32, 33, 34, 36, 38, 39, 40, 46, 48, 49, 50, 51, 52, 53, 54, 58, 61, 62], [2, 5, 6, 9, 11, 15, 17, 18, 19, 21, 22, 23, 24, 27, 28, 29, 31, 33, 37, 38, 39, 40, 41, 42, 44, 45, 46, 47, 48, 50, 51, 52, 54, 55, 56, 59, 60, 62], [0, 1, 2, 5, 6, 9, 10, 11, 13, 16, 17, 19, 20, 21, 23, 24, 28, 29, 31, 33, 36, 38, 44, 45, 46, 47, 52, 56, 59, 60, 61, 62], [0, 1, 3, 6, 7, 8, 9, 11, 12, 16, 17, 23, 25, 26, 27, 28, 31, 32, 34, 35, 36, 37, 40, 41, 43, 47, 49, 50, 51, 53, 54, 57, 58, 61, 62]]\n",
      "Completed training classifier 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "Completed training classifier 5\n",
      "Completed training classifier 6\n",
      "Completed training classifier 7\n",
      "Completed training classifier 8\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.9444444444444444, 0.9696969696969697, 0.9411764705882353, 0.9, 0.8108108108108109, 0.9166666666666666, 0.9473684210526315, 0.78125, 0.9428571428571428]\n",
      "Average Accuracy of classifiers:  0.9060301029018779\n",
      "\n",
      "yhat:  [2. 2. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 1. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 9, bootstrap_ratio=0.6): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.94      0.89      0.91        18\n",
      "           2       0.83      0.91      0.87        11\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.92      0.93      0.93        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  73\n",
      "not used indexes:  [[0, 5, 6, 7, 8, 11, 17, 22, 23, 24, 29, 30, 31, 35, 36, 37, 40, 41, 42, 45, 46, 48, 49, 51, 52, 53, 54, 56, 57, 59, 62, 64, 65, 66, 67, 71], [0, 1, 2, 6, 9, 11, 12, 13, 17, 21, 23, 27, 28, 30, 36, 41, 42, 43, 45, 51, 53, 55, 56, 57, 58, 59, 61, 62, 64, 65, 66, 67, 70, 71], [2, 5, 8, 10, 14, 16, 17, 19, 21, 23, 25, 26, 28, 30, 31, 34, 35, 37, 38, 43, 45, 46, 48, 49, 52, 53, 54, 55, 57, 62, 63, 64, 66, 68, 72], [2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 15, 18, 19, 20, 22, 26, 27, 30, 31, 34, 35, 36, 37, 38, 40, 47, 48, 49, 51, 53, 54, 58, 59, 60, 61, 62, 64, 65, 66, 68, 70, 72], [4, 6, 7, 8, 10, 15, 19, 21, 23, 26, 28, 30, 33, 35, 36, 37, 38, 40, 41, 42, 47, 50, 52, 53, 54, 55, 56, 57, 59, 60, 61, 63, 65, 68, 69], [0, 1, 2, 6, 7, 9, 11, 12, 13, 16, 17, 18, 20, 21, 22, 24, 25, 26, 29, 32, 33, 34, 35, 40, 42, 43, 47, 51, 52, 54, 57, 59, 60, 61, 62, 63, 66, 68], [0, 1, 4, 5, 8, 11, 13, 17, 31, 32, 33, 34, 37, 40, 42, 43, 44, 46, 47, 48, 50, 51, 52, 53, 56, 57, 59, 61, 64, 67, 70, 72], [1, 5, 8, 9, 10, 12, 16, 17, 18, 21, 24, 28, 29, 32, 35, 36, 37, 38, 39, 41, 42, 47, 51, 52, 53, 56, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69, 70], [2, 3, 8, 11, 12, 13, 14, 16, 17, 19, 20, 21, 26, 29, 31, 33, 38, 39, 44, 47, 48, 51, 53, 54, 56, 58, 59, 62, 66, 67, 68, 69]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "Completed training classifier 5\n",
      "Completed training classifier 6\n",
      "Completed training classifier 7\n",
      "Completed training classifier 8\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.9444444444444444, 0.8823529411764706, 0.9142857142857143, 0.9302325581395349, 0.9142857142857143, 0.9210526315789473, 0.9375, 0.9459459459459459, 0.9375]\n",
      "Average Accuracy of classifiers:  0.9252888833174191\n",
      "\n",
      "yhat:  [2. 1. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 9, bootstrap_ratio=0.7): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  84\n",
      "not used indexes:  [[2, 4, 5, 7, 15, 16, 17, 18, 25, 26, 27, 28, 32, 36, 38, 40, 45, 48, 50, 51, 52, 56, 57, 58, 61, 64, 66, 69, 72, 73, 74, 76, 83], [2, 7, 8, 14, 15, 18, 20, 23, 24, 25, 27, 30, 31, 34, 36, 40, 43, 44, 45, 46, 48, 51, 52, 54, 58, 61, 63, 68, 69, 70, 71, 72, 73, 76, 77], [0, 8, 9, 13, 14, 18, 25, 29, 31, 34, 37, 38, 39, 40, 42, 43, 45, 46, 53, 54, 57, 62, 64, 65, 69, 70, 71, 72, 73, 74, 75, 77, 79, 80], [1, 2, 4, 6, 7, 10, 11, 12, 17, 20, 25, 30, 31, 33, 37, 39, 41, 47, 48, 49, 50, 51, 52, 55, 59, 61, 62, 64, 65, 70, 71, 73, 74, 75, 78, 79, 80, 82], [0, 2, 3, 5, 6, 7, 10, 11, 12, 13, 16, 18, 19, 25, 27, 29, 30, 32, 33, 35, 36, 37, 41, 43, 49, 55, 58, 60, 61, 62, 63, 67, 71, 74, 75, 76, 77, 78, 81], [0, 2, 4, 6, 7, 12, 13, 15, 16, 17, 18, 21, 24, 29, 30, 33, 35, 38, 41, 43, 44, 50, 51, 53, 54, 59, 61, 62, 65, 66, 67, 70, 72, 75, 76, 77, 80, 81, 83], [0, 2, 4, 5, 6, 9, 10, 12, 13, 14, 15, 19, 22, 25, 27, 29, 30, 35, 37, 39, 47, 48, 49, 50, 53, 55, 56, 58, 68, 72, 74, 80, 81, 83], [2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 20, 24, 30, 33, 34, 35, 36, 37, 39, 40, 42, 45, 46, 55, 57, 59, 61, 66, 71, 72, 78, 79, 80, 82], [2, 3, 4, 6, 10, 12, 13, 14, 15, 17, 19, 20, 21, 22, 23, 25, 27, 33, 40, 50, 51, 54, 55, 56, 58, 62, 63, 64, 70, 71, 72, 74, 81, 82]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "Completed training classifier 5\n",
      "Completed training classifier 6\n",
      "Completed training classifier 7\n",
      "Completed training classifier 8\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.8181818181818182, 0.9428571428571428, 0.9411764705882353, 0.9736842105263158, 0.9487179487179487, 0.9743589743589743, 0.9705882352941176, 0.9722222222222222, 0.9705882352941176]\n",
      "Average Accuracy of classifiers:  0.9458194731156547\n",
      "\n",
      "yhat:  [2. 1. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 9, bootstrap_ratio=0.8): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  94\n",
      "not used indexes:  [[7, 8, 10, 12, 15, 20, 23, 24, 28, 31, 35, 37, 39, 40, 42, 44, 45, 46, 48, 51, 52, 56, 59, 60, 63, 64, 65, 66, 71, 73, 74, 78, 79, 80, 82, 83, 84, 86, 88, 93], [4, 6, 8, 10, 13, 15, 16, 18, 20, 21, 22, 23, 24, 26, 27, 32, 34, 35, 39, 40, 45, 46, 49, 53, 54, 55, 56, 61, 64, 67, 74, 82, 86, 87, 88, 90, 92], [1, 4, 8, 9, 10, 16, 18, 19, 22, 25, 26, 27, 28, 29, 31, 32, 37, 43, 47, 48, 51, 52, 57, 62, 64, 66, 68, 69, 70, 72, 75, 82, 83, 84, 85, 86, 89, 92], [1, 2, 3, 6, 7, 8, 12, 14, 18, 19, 30, 31, 33, 36, 39, 42, 43, 46, 50, 51, 54, 55, 56, 58, 59, 60, 61, 63, 64, 65, 68, 69, 72, 75, 79, 80, 88, 90, 92], [1, 2, 4, 8, 10, 11, 12, 13, 16, 17, 22, 24, 25, 27, 29, 32, 34, 35, 36, 37, 38, 40, 41, 42, 44, 45, 51, 55, 56, 61, 64, 66, 68, 69, 75, 77, 78, 82, 85, 86, 87, 90], [1, 3, 7, 14, 15, 16, 17, 19, 20, 23, 24, 26, 29, 33, 36, 38, 39, 41, 44, 45, 46, 49, 58, 60, 61, 65, 69, 71, 74, 78, 79, 80, 81, 82, 83, 86, 88], [3, 5, 8, 9, 11, 17, 19, 21, 22, 27, 28, 29, 30, 31, 33, 34, 37, 38, 40, 43, 44, 50, 51, 54, 59, 62, 69, 74, 79, 82, 89, 92], [1, 2, 4, 8, 9, 11, 12, 15, 17, 18, 19, 24, 26, 28, 37, 39, 42, 45, 51, 54, 55, 60, 62, 65, 68, 69, 71, 79, 83, 86, 88, 89, 90, 91, 92], [3, 5, 9, 10, 11, 12, 15, 17, 23, 26, 27, 28, 31, 34, 37, 40, 43, 46, 48, 50, 52, 53, 55, 56, 58, 60, 64, 66, 68, 70, 74, 80, 81, 83, 84, 85, 86, 87, 88, 92]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "Completed training classifier 5\n",
      "Completed training classifier 6\n",
      "Completed training classifier 7\n",
      "Completed training classifier 8\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.975, 0.9459459459459459, 0.7631578947368421, 0.8461538461538461, 0.8095238095238095, 0.918918918918919, 0.90625, 0.9428571428571428, 0.925]\n",
      "Average Accuracy of classifiers:  0.8925341731262785\n",
      "\n",
      "yhat:  [2. 1. 0. 2. 1. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 9, bootstrap_ratio=0.9): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.94      0.94      0.94        18\n",
      "           2       0.91      0.91      0.91        11\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.95      0.95      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  105\n",
      "not used indexes:  [[0, 2, 5, 8, 9, 11, 20, 25, 26, 29, 31, 32, 37, 38, 39, 40, 41, 43, 45, 46, 48, 49, 50, 51, 52, 54, 62, 66, 68, 69, 72, 75, 78, 80, 82, 86, 95, 97, 98, 99], [2, 3, 4, 20, 24, 26, 27, 29, 31, 34, 35, 36, 39, 41, 45, 46, 47, 48, 50, 51, 53, 60, 61, 62, 63, 65, 68, 73, 76, 85, 93, 95, 97, 102], [2, 3, 15, 16, 19, 22, 23, 24, 26, 27, 30, 34, 37, 44, 47, 48, 51, 53, 57, 58, 66, 69, 75, 76, 82, 83, 85, 87, 89, 95, 100, 101, 102], [3, 4, 7, 8, 9, 13, 15, 16, 17, 18, 25, 28, 33, 43, 45, 48, 51, 53, 56, 60, 66, 69, 71, 72, 73, 74, 75, 77, 79, 80, 86, 87, 89, 92, 93, 94, 97, 99, 101, 103], [1, 4, 5, 6, 8, 10, 13, 14, 21, 30, 36, 38, 40, 43, 46, 48, 49, 60, 61, 62, 65, 66, 67, 69, 71, 74, 76, 77, 78, 80, 84, 85, 86, 88, 93, 95, 97, 99, 101, 102, 103], [3, 4, 5, 6, 11, 13, 21, 29, 31, 32, 33, 34, 35, 36, 38, 41, 44, 46, 47, 50, 59, 63, 64, 65, 66, 69, 72, 74, 75, 76, 77, 79, 81, 85, 87, 90, 92, 94, 96, 97, 98, 101, 104], [0, 3, 4, 7, 8, 10, 14, 16, 18, 22, 28, 29, 33, 35, 44, 46, 47, 48, 49, 51, 54, 55, 60, 62, 64, 66, 69, 70, 75, 76, 77, 84, 89, 91, 92, 94, 95, 99, 102, 104], [0, 3, 4, 7, 11, 14, 16, 19, 20, 21, 22, 24, 25, 27, 30, 32, 37, 45, 47, 48, 53, 54, 55, 64, 70, 71, 76, 77, 80, 81, 82, 84, 91, 92, 93, 94, 96, 97, 98, 104], [5, 6, 16, 19, 22, 23, 28, 29, 31, 35, 36, 42, 43, 44, 46, 47, 49, 52, 53, 58, 62, 64, 66, 67, 70, 77, 80, 84, 91, 97, 98, 99, 100, 102, 103, 104]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "Completed training classifier 5\n",
      "Completed training classifier 6\n",
      "Completed training classifier 7\n",
      "Completed training classifier 8\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.9, 0.9117647058823529, 0.8181818181818182, 0.95, 0.926829268292683, 0.8837209302325582, 0.95, 0.875, 0.9166666666666666]\n",
      "Average Accuracy of classifiers:  0.903573709917342\n",
      "\n",
      "yhat:  [2. 1. 0. 2. 1. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 9, bootstrap_ratio=1.0): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.94      0.94      0.94        18\n",
      "           2       0.91      0.91      0.91        11\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.95      0.95      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  63\n",
      "not used indexes:  [[2, 3, 5, 6, 8, 10, 11, 12, 13, 14, 16, 19, 22, 24, 25, 26, 28, 29, 32, 33, 36, 37, 38, 40, 41, 43, 47, 48, 50, 52, 53, 55, 56, 57, 59, 61], [3, 5, 9, 13, 14, 17, 20, 21, 22, 24, 25, 27, 28, 30, 31, 32, 35, 36, 37, 38, 39, 40, 42, 43, 46, 47, 48, 49, 51, 54, 55, 56, 57, 61], [0, 1, 2, 4, 5, 7, 8, 9, 10, 11, 14, 15, 16, 18, 19, 21, 22, 23, 24, 26, 27, 28, 29, 30, 31, 33, 35, 36, 37, 38, 41, 45, 46, 49, 50, 51, 53, 55, 56, 57, 58, 60, 62], [0, 2, 4, 5, 6, 7, 8, 10, 12, 13, 16, 17, 19, 20, 22, 23, 24, 25, 28, 32, 34, 36, 37, 39, 40, 41, 42, 44, 50, 52, 54, 57, 58, 59, 62], [0, 1, 3, 4, 7, 11, 13, 15, 16, 17, 19, 21, 22, 24, 25, 26, 27, 30, 33, 34, 35, 36, 40, 45, 46, 47, 48, 49, 50, 51, 53, 55, 57, 58, 60, 61], [1, 3, 4, 6, 9, 10, 11, 12, 13, 15, 17, 20, 22, 23, 25, 26, 29, 30, 33, 34, 35, 37, 39, 40, 41, 42, 44, 45, 46, 49, 52, 55, 56, 57, 58, 60, 61, 62], [0, 1, 3, 8, 11, 12, 14, 16, 20, 22, 23, 24, 25, 27, 28, 29, 30, 32, 33, 34, 37, 38, 41, 44, 45, 46, 47, 48, 49, 53, 56, 58], [0, 1, 3, 4, 5, 7, 9, 12, 13, 20, 21, 23, 24, 26, 27, 28, 29, 32, 34, 35, 36, 39, 42, 44, 46, 48, 50, 55, 59, 60, 62], [8, 11, 13, 14, 15, 18, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 36, 37, 38, 42, 43, 44, 45, 46, 47, 48, 50, 51, 53, 54, 55, 56, 59, 60, 62], [0, 5, 7, 8, 9, 10, 11, 13, 14, 15, 16, 18, 20, 22, 25, 29, 33, 34, 35, 37, 39, 40, 41, 42, 45, 46, 47, 52, 53, 54, 55, 56, 58, 59, 60, 61]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "Completed training classifier 5\n",
      "Completed training classifier 6\n",
      "Completed training classifier 7\n",
      "Completed training classifier 8\n",
      "Completed training classifier 9\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.8888888888888888, 0.9411764705882353, 0.7906976744186046, 0.9142857142857143, 0.9166666666666666, 0.868421052631579, 0.9375, 0.9354838709677419, 0.8888888888888888, 0.9444444444444444]\n",
      "Average Accuracy of classifiers:  0.9026453671780764\n",
      "\n",
      "yhat:  [2. 2. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 1. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 10, bootstrap_ratio=0.6): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.94      0.89      0.91        18\n",
      "           2       0.83      0.91      0.87        11\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.92      0.93      0.93        45\n",
      "weighted avg       0.94      0.93      0.93        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  73\n",
      "not used indexes:  [[1, 2, 3, 4, 7, 12, 15, 18, 19, 21, 24, 26, 27, 28, 29, 33, 34, 38, 40, 41, 42, 45, 46, 49, 50, 51, 54, 58, 61, 63, 66, 68, 71, 72], [3, 4, 6, 7, 8, 9, 12, 13, 16, 23, 25, 28, 30, 32, 33, 34, 35, 40, 42, 43, 47, 49, 50, 52, 54, 55, 57, 60, 66, 67, 69, 70, 72], [2, 3, 6, 7, 10, 11, 16, 17, 18, 19, 22, 24, 25, 26, 27, 28, 29, 31, 35, 38, 42, 43, 46, 48, 49, 51, 53, 56, 57, 58, 59, 60, 61, 62, 65, 66, 69, 71, 72], [0, 1, 4, 7, 8, 9, 11, 14, 15, 16, 17, 18, 20, 23, 25, 26, 29, 31, 36, 39, 40, 41, 42, 45, 51, 55, 56, 57, 59, 62, 64, 65, 66, 68, 71, 72], [1, 3, 4, 8, 9, 10, 13, 16, 20, 21, 23, 27, 28, 30, 32, 37, 38, 40, 47, 48, 49, 52, 55, 57, 58, 60, 61, 62, 63, 64, 65, 68, 70, 72], [2, 3, 4, 6, 7, 8, 12, 13, 15, 16, 17, 19, 20, 21, 25, 26, 27, 28, 32, 34, 35, 39, 42, 44, 47, 49, 50, 55, 58, 59, 62, 63, 64, 65, 67, 68], [0, 4, 7, 13, 14, 17, 18, 19, 22, 23, 25, 26, 27, 29, 30, 31, 35, 39, 40, 41, 47, 48, 50, 52, 53, 54, 56, 57, 59, 60, 62, 64, 65, 67, 68, 70, 71], [0, 1, 2, 5, 6, 7, 8, 11, 12, 13, 18, 20, 24, 25, 28, 31, 33, 35, 37, 40, 42, 43, 44, 45, 49, 52, 55, 56, 57, 59, 61, 67, 69], [0, 1, 2, 3, 4, 6, 7, 8, 10, 11, 12, 15, 17, 18, 21, 25, 27, 28, 29, 32, 33, 37, 38, 39, 42, 45, 46, 48, 51, 55, 58, 60, 63, 65, 67, 69, 70], [0, 2, 5, 6, 8, 9, 10, 11, 12, 16, 19, 20, 21, 25, 29, 30, 34, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 51, 52, 53, 56, 57, 58, 59, 63, 65, 67, 70, 71]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "Completed training classifier 5\n",
      "Completed training classifier 6\n",
      "Completed training classifier 7\n",
      "Completed training classifier 8\n",
      "Completed training classifier 9\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.9117647058823529, 0.9393939393939394, 0.9487179487179487, 0.8888888888888888, 0.9411764705882353, 0.9722222222222222, 0.918918918918919, 0.9393939393939394, 0.918918918918919, 0.9512195121951219]\n",
      "Average Accuracy of classifiers:  0.9330615465120486\n",
      "\n",
      "yhat:  [2. 1. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 1. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 10, bootstrap_ratio=0.7): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.94      0.94      0.94        18\n",
      "           2       0.91      0.91      0.91        11\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.95      0.95      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  84\n",
      "not used indexes:  [[4, 6, 7, 10, 13, 14, 15, 16, 17, 19, 20, 24, 27, 28, 30, 32, 33, 35, 37, 41, 42, 43, 54, 58, 59, 60, 61, 62, 65, 66, 69, 70, 73, 74, 77, 78, 79, 81], [0, 2, 3, 4, 6, 7, 11, 12, 15, 16, 22, 30, 33, 37, 38, 39, 42, 44, 47, 49, 52, 56, 58, 59, 63, 64, 65, 66, 70, 71, 73, 74, 77, 79, 80, 83], [1, 2, 7, 8, 9, 10, 14, 15, 17, 18, 19, 22, 23, 26, 28, 31, 40, 41, 51, 52, 56, 61, 62, 63, 64, 65, 67, 76, 77, 78], [4, 5, 7, 8, 12, 15, 17, 18, 19, 20, 22, 24, 31, 32, 33, 36, 38, 39, 41, 45, 50, 53, 54, 58, 60, 63, 64, 65, 66, 67, 68, 70, 71, 74, 78, 82, 83], [0, 1, 5, 16, 23, 26, 31, 32, 34, 35, 39, 40, 41, 42, 46, 47, 48, 49, 50, 53, 54, 55, 57, 58, 60, 61, 62, 63, 72, 74, 75, 77, 79, 80, 81], [2, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 26, 29, 34, 42, 43, 45, 47, 48, 49, 50, 51, 52, 53, 55, 56, 61, 62, 65, 72, 75, 77, 78, 81, 82], [5, 10, 12, 13, 15, 16, 20, 21, 22, 23, 25, 27, 28, 29, 30, 33, 34, 35, 36, 38, 39, 40, 42, 44, 45, 49, 50, 51, 52, 53, 55, 56, 58, 64, 68, 69, 71, 76, 83], [0, 1, 4, 6, 9, 12, 13, 17, 18, 19, 20, 23, 24, 26, 27, 30, 32, 33, 34, 36, 39, 41, 42, 43, 45, 46, 47, 49, 52, 58, 64, 65, 66, 68, 69, 70, 74, 75, 76, 78, 79, 83], [1, 4, 6, 7, 8, 10, 11, 13, 14, 16, 17, 19, 20, 21, 23, 25, 26, 30, 33, 34, 44, 45, 46, 47, 48, 50, 52, 55, 57, 60, 61, 63, 64, 68, 71, 74, 80], [0, 6, 7, 10, 13, 17, 21, 23, 24, 25, 26, 28, 30, 34, 35, 36, 37, 39, 43, 44, 48, 52, 54, 56, 60, 62, 63, 66, 69, 70, 71, 73, 74, 76, 78, 80, 81, 82]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "Completed training classifier 5\n",
      "Completed training classifier 6\n",
      "Completed training classifier 7\n",
      "Completed training classifier 8\n",
      "Completed training classifier 9\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.6842105263157895, 0.9444444444444444, 0.9333333333333333, 0.972972972972973, 0.9428571428571428, 0.9487179487179487, 0.7948717948717948, 0.8333333333333334, 0.9459459459459459, 0.8421052631578947]\n",
      "Average Accuracy of classifiers:  0.8842792705950601\n",
      "\n",
      "yhat:  [2. 1. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 10, bootstrap_ratio=0.8): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  94\n",
      "not used indexes:  [[0, 1, 2, 5, 6, 14, 15, 16, 17, 18, 25, 28, 29, 30, 32, 34, 37, 42, 44, 45, 46, 47, 48, 50, 52, 54, 58, 60, 61, 62, 63, 65, 67, 68, 70, 72, 73, 79, 84, 85, 86, 90, 91], [2, 3, 5, 6, 8, 11, 15, 16, 17, 18, 20, 22, 24, 28, 29, 31, 32, 34, 35, 37, 47, 49, 51, 59, 61, 65, 68, 69, 70, 72, 74, 80, 81, 82, 88, 89, 91, 92], [0, 2, 3, 4, 5, 8, 9, 16, 18, 22, 23, 24, 25, 32, 33, 35, 40, 50, 51, 54, 55, 57, 60, 63, 64, 66, 69, 75, 76, 77, 78, 79, 85, 88, 91], [0, 3, 4, 9, 14, 16, 18, 20, 22, 23, 34, 36, 38, 40, 44, 48, 49, 51, 53, 54, 58, 65, 67, 68, 70, 73, 74, 76, 77, 78, 82, 83, 86, 87, 90, 92, 93], [0, 4, 5, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18, 23, 25, 28, 30, 31, 34, 40, 41, 49, 51, 53, 55, 56, 57, 60, 61, 70, 73, 74, 76, 77, 80, 83, 89], [0, 2, 3, 5, 9, 15, 17, 22, 24, 26, 27, 34, 38, 43, 50, 51, 54, 58, 59, 60, 61, 63, 65, 66, 70, 72, 73, 75, 77, 78, 79, 80, 84, 91, 93], [2, 5, 6, 7, 8, 9, 15, 16, 18, 20, 21, 22, 25, 28, 29, 31, 32, 33, 36, 40, 41, 51, 52, 61, 68, 69, 75, 76, 84, 87, 88, 91], [0, 2, 3, 11, 12, 15, 20, 21, 22, 26, 33, 37, 39, 41, 44, 47, 49, 50, 53, 55, 58, 64, 65, 67, 69, 72, 75, 77, 85, 87, 89, 90, 92], [1, 2, 5, 8, 9, 11, 13, 14, 16, 17, 21, 22, 23, 27, 31, 33, 35, 36, 38, 40, 42, 44, 45, 50, 52, 55, 56, 60, 64, 67, 68, 71, 75, 76, 78, 81, 82, 83, 87, 91, 92, 93], [2, 3, 5, 9, 10, 11, 19, 21, 23, 24, 28, 35, 37, 39, 42, 43, 44, 47, 50, 53, 57, 58, 64, 66, 69, 71, 73, 74, 75, 76, 78, 80, 82, 83, 86, 89, 90, 91, 92]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "Completed training classifier 5\n",
      "Completed training classifier 6\n",
      "Completed training classifier 7\n",
      "Completed training classifier 8\n",
      "Completed training classifier 9\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.9302325581395349, 0.7894736842105263, 0.9428571428571428, 0.9459459459459459, 0.918918918918919, 0.9428571428571428, 0.90625, 0.9696969696969697, 0.9761904761904762, 1.0]\n",
      "Average Accuracy of classifiers:  0.9322422838816659\n",
      "\n",
      "yhat:  [2. 1. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 10, bootstrap_ratio=0.9): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "Bagging with replacement:  True\n",
      "Using sample size:  105\n",
      "not used indexes:  [[1, 3, 11, 13, 17, 21, 24, 25, 26, 30, 31, 33, 35, 37, 38, 39, 42, 46, 52, 53, 54, 56, 61, 68, 70, 72, 73, 78, 82, 84, 88, 89, 91, 92, 95, 98, 99, 100, 102], [2, 4, 11, 12, 13, 14, 17, 20, 23, 25, 27, 28, 29, 30, 31, 33, 34, 36, 38, 39, 46, 47, 51, 53, 55, 57, 58, 59, 60, 62, 63, 65, 69, 70, 74, 77, 80, 81, 91, 92, 96, 103], [4, 19, 21, 22, 28, 30, 34, 35, 38, 43, 45, 47, 48, 52, 54, 60, 62, 64, 65, 66, 67, 68, 70, 76, 78, 79, 80, 82, 86, 91, 92, 94, 95, 96, 98, 99, 101, 103], [1, 3, 4, 9, 14, 17, 21, 23, 27, 28, 30, 38, 39, 40, 43, 45, 47, 48, 50, 51, 52, 54, 55, 57, 62, 65, 68, 74, 75, 76, 78, 82, 85, 90, 93, 95, 97, 98, 103, 104], [0, 1, 4, 5, 6, 7, 10, 11, 12, 13, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 35, 38, 40, 42, 51, 52, 55, 57, 58, 59, 61, 62, 64, 66, 70, 72, 77, 78, 81, 87, 91, 97, 102, 104], [1, 2, 3, 6, 8, 9, 11, 12, 13, 14, 20, 22, 24, 27, 28, 31, 33, 35, 42, 43, 44, 46, 47, 51, 53, 55, 56, 63, 65, 68, 76, 78, 83, 84, 85, 86, 93, 97, 98, 99, 101], [0, 7, 10, 13, 15, 18, 19, 21, 23, 25, 26, 29, 30, 34, 36, 38, 41, 43, 51, 53, 55, 56, 59, 61, 65, 66, 67, 72, 73, 77, 82, 85, 86, 88, 89, 96, 103, 104], [0, 4, 5, 7, 9, 11, 12, 13, 15, 16, 27, 31, 35, 36, 38, 39, 41, 47, 50, 54, 58, 60, 64, 65, 68, 70, 71, 73, 74, 81, 82, 83, 84, 86, 87, 89, 90, 91, 92, 95, 96, 97, 102, 103], [0, 1, 6, 7, 8, 15, 19, 20, 22, 25, 26, 28, 30, 34, 35, 37, 38, 41, 48, 51, 54, 59, 62, 68, 71, 74, 75, 76, 79, 82, 84, 85, 86, 87, 88, 89, 91, 93, 95, 103], [12, 13, 17, 19, 21, 22, 24, 27, 29, 31, 34, 35, 37, 41, 42, 44, 49, 50, 56, 60, 63, 67, 68, 69, 72, 73, 74, 79, 82, 91, 92, 96, 98, 100, 102, 104]]\n",
      "Completed training classifier 0\n",
      "Completed training classifier 1\n",
      "Completed training classifier 2\n",
      "Completed training classifier 3\n",
      "Completed training classifier 4\n",
      "Completed training classifier 5\n",
      "Completed training classifier 6\n",
      "Completed training classifier 7\n",
      "Completed training classifier 8\n",
      "Completed training classifier 9\n",
      "\n",
      "Accuracy of classifiers using oob training data:  [0.9743589743589743, 0.9285714285714286, 0.9736842105263158, 0.925, 0.9545454545454546, 0.8048780487804879, 0.9736842105263158, 0.9772727272727273, 0.925, 0.9166666666666666]\n",
      "Average Accuracy of classifiers:  0.935366172124837\n",
      "\n",
      "yhat:  [2. 1. 0. 2. 2. 0. 0. 2. 0. 1. 0. 2. 0. 1. 0. 0. 1. 0. 0. 2. 1. 1. 0. 2.\n",
      " 1. 0. 1. 2. 2. 1. 0. 1. 0. 2. 1. 0. 1. 0. 2. 1. 1. 2. 1. 1. 1.]\n",
      "\n",
      "Accuracy with Bagging (trees = 10, bootstrap_ratio=1.0): \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for n_trees in [4, 5, 6, 7, 8, 9, 10]:\n",
    "    for sample_ratio in [0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "        model=bagging(b=n_trees, bootstrap_ratio=sample_ratio )\n",
    "        model.fit(X_train, y_train, with_replacement=True)\n",
    "        yhat=model.predict(X_test)\n",
    "        print(\"\\nyhat: \", yhat)\n",
    "        print(f\"\\nAccuracy with Bagging (trees = {n_trees}, bootstrap_ratio={sample_ratio}): \")\n",
    "        print(classification_report(y_test, yhat))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonDSAI",
   "language": "python",
   "name": "pythondsai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
